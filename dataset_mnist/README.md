# Dataset Mnist

Este proyecto implementa una red neuronal en Rust para clasificar imÃ¡genes de dÃ­gitos escritos a mano del dataset MNIST. El cÃ³digo estÃ¡ autocontenido y no depende de frameworks externos de machine learning.

## ExplicaciÃ³n del CÃ³digo

El archivo `src/main.rs` contiene la implementaciÃ³n completa de la red neuronal y el ciclo de entrenamiento. Los componentes principales son:

-   **`NeuralNetwork`**: Estructura principal que define la red, incluyendo sus capas y el optimizador.
-   **`Layer`**: Define una capa de neuronas, con sus pesos, sesgos y funciones de activaciÃ³n (ReLU para capas ocultas y Softmax para la capa de salida).
-   **`AdamOptimizer`**: Implementa el optimizador Adam para ajustar eficientemente los pesos de la red durante el entrenamiento.
-   **`train` y `validate`**: Funciones que manejan el ciclo de entrenamiento y la evaluaciÃ³n del modelo contra un conjunto de datos de validaciÃ³n.
-   **`load_mnist_from_png_improved`**: FunciÃ³n encargada de cargar las imÃ¡genes PNG, procesarlas, normalizar los valores de los pÃ­xeles y dividirlas en conjuntos de entrenamiento y validaciÃ³n.
-   **`plot_training_metrics`**: Utiliza la librerÃ­a `plotters` para generar grÃ¡ficos que muestran la pÃ©rdida (loss) y la precisiÃ³n (accuracy) a lo largo de las Ã©pocas de entrenamiento.

## Â¿QuÃ© aprendimos aquÃ­?

A travÃ©s de este ejemplo, podemos aprender varios conceptos fundamentales del deep learning:

1.  **Arquitectura de una Red Neuronal**: CÃ³mo estructurar capas de neuronas para procesar datos complejos como imÃ¡genes.
2.  **Forward y Backward Propagation**: El proceso de pasar datos a travÃ©s de la red para hacer una predicciÃ³n (forward) y luego calcular los errores para ajustar los pesos (backward).
3.  **Funciones de ActivaciÃ³n**: La importancia de funciones no lineales como ReLU y cÃ³mo Softmax es Ãºtil para problemas de clasificaciÃ³n multiclase.
4.  **OptimizaciÃ³n**: CÃ³mo algoritmos como Adam ayudan a la red a converger hacia una soluciÃ³n Ã³ptima de manera mÃ¡s rÃ¡pida y estable que un descenso de gradiente estÃ¡ndar.
5.  **Ciclo de Vida de un Modelo**: El proceso completo de cargar datos, entrenar un modelo, validarlo para evitar el sobreajuste (overfitting) y visualizar su rendimiento.
6.  **Procesamiento de Datos**: La importancia de normalizar los datos de entrada para mejorar el rendimiento y la estabilidad del entrenamiento.

## Estructura de la Carpeta del Proyecto

```
dataset_mnist/
â”œâ”€â”€ Cargo.lock
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ content.json
â”œâ”€â”€ mnist_small_dataset_metrics.png
â”œâ”€â”€ mnist_training_metrics.png
â”œâ”€â”€ README.md
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main.rs
â””â”€â”€ public/
    â””â”€â”€ train/
       â”œâ”€â”€ 0/
       â”œâ”€â”€ 1/
       â””â”€â”€ ... (mÃ¡s carpetas por dÃ­gito)
```

## ConfiguraciÃ³n del Dataset

**Importante**: El dataset de imÃ¡genes MNIST no se incluye en este repositorio debido a su tamaÃ±o. Sin embargo, puedes descargarlo y configurarlo fÃ¡cilmente.

1.  **Descarga el dataset** desde el siguiente enlace de Kaggle, que contiene las imÃ¡genes en formato `.zip`:
    *   [https://www.kaggle.com/datasets/playlist/mnistzip](https://www.kaggle.com/datasets/playlist/mnistzip)

2.  **Estructura de carpetas**: Descomprime los archivos y organÃ­zalos dentro de la carpeta `public/` siguiendo la estructura mostrada arriba. Debes tener una carpeta `train` y una `valid` (o solo `train` si prefieres que el cÃ³digo haga la divisiÃ³n automÃ¡ticamente), y dentro de ellas, subcarpetas nombradas del `0` al `9` que contengan las imÃ¡genes correspondientes a cada dÃ­gito.

Al finalizar el entrenamiento, el programa generarÃ¡ una imagen llamada `mnist_training_metrics.png` con los grÃ¡ficos de rendimiento del modelo, similar a esta:

### ConfiguraciÃ³n del Test

ğŸ”„ Procesando: 9/9998.png (28x28) 

ğŸ“¸ Procesando: public/train/9/9998.png

    ğŸ“Š EstadÃ­sticas de 9998.png: Media=0.404, Std=0.266, Min=-0.500, Max=0.500, PÃ­xeles activos=739/784
    âœ… Cargada como dÃ­gito 9

ğŸ‰ === Datos Cargados Exitosamente ===

ğŸ“ˆ Total de muestras: 60000

ğŸ“Š AnÃ¡lisis EstadÃ­stico del Dataset:

  ğŸ“‹ DistribuciÃ³n por clase:

    DÃ­gito 0: 5923 muestras
    DÃ­gito 1: 6742 muestras
    DÃ­gito 2: 5958 muestras
    DÃ­gito 3: 6131 muestras
    DÃ­gito 4: 5842 muestras
    DÃ­gito 5: 5421 muestras
    DÃ­gito 6: 5918 muestras
    DÃ­gito 7: 6265 muestras
    DÃ­gito 8: 5851 muestras
    DÃ­gito 9: 5949 muestras

  ğŸ“ˆ EstadÃ­sticas globales de pÃ­xeles:

    Media: 0.3693
    DesviaciÃ³n estÃ¡ndar: 0.3081
    Rango: [-0.5000, 0.5000]

ğŸ“Š DivisiÃ³n Final:

  ğŸ‹ï¸  Entrenamiento: 48000 muestras (80.0%)

  ğŸ§ª ValidaciÃ³n: 12000 muestras (20.0%)

âš™ï¸  ConfiguraciÃ³n para dataset de 60000 muestras:

  ğŸ—ï¸  Arquitectura: 784 -> 128 -> 64 -> 10
  ğŸ“š Tasa de aprendizaje: 0.001
  ğŸ”„ Ã‰pocas: 500
  ğŸ“¦ TamaÃ±o de batch: 4

ğŸ§  Creando red neuronal...


