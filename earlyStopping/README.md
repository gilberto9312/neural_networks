# ğŸ§  DÃ­a 11: Early Stopping (Parada Temprana)

Una implementaciÃ³n en Rust que demuestra cÃ³mo utilizar **Early Stopping** para prevenir el sobreajuste y optimizar el tiempo de entrenamiento en una red neuronal.

## ğŸ¯ DescripciÃ³n

Este proyecto implementa una red neuronal desde cero para resolver el problema XOR. El objetivo principal es mostrar cÃ³mo la tÃ©cnica de **Early Stopping** puede detener el entrenamiento de manera inteligente cuando el rendimiento en un conjunto de validaciÃ³n deja de mejorar, evitando asÃ­ el sobreajuste y ahorrando ciclos de computaciÃ³n.

Se comparan varios escenarios para evaluar el impacto de esta tÃ©cnica:
1.  Entrenamiento sin Early Stopping (lÃ­nea de base).
2.  Entrenamiento con Early Stopping "conservador" (paciencia alta).
3.  Entrenamiento con Early Stopping "agresivo" (paciencia baja).
4.  CombinaciÃ³n de Early Stopping con otras tÃ©cnicas de regularizaciÃ³n como **L2** y **Dropout**.

## ğŸ—ï¸ Arquitectura de la Red

-   **Capa de entrada**: 2 neuronas
-   **Capa oculta**: 8 neuronas (funciÃ³n de activaciÃ³n: Sigmoid)
-   **Capa de salida**: 1 neurona (funciÃ³n de activaciÃ³n: Sigmoid)
-   **InicializaciÃ³n**: Pesos aleatorios con una semilla fija para garantizar la reproducibilidad de los experimentos.
-   **Optimizador**: Se utiliza **Adam** en todos los escenarios por su eficiencia y robustez.

## ğŸš€ TÃ©cnica: Early Stopping

El Early Stopping es una forma de regularizaciÃ³n que monitoriza el rendimiento del modelo en un conjunto de datos de validaciÃ³n.

### Â¿CÃ³mo funciona?

1.  **MonitorizaciÃ³n**: DespuÃ©s de cada Ã©poca, se calcula el error (pÃ©rdida) del modelo en el conjunto de validaciÃ³n.
2.  **Paciencia (`patience`)**: Se define un nÃºmero de Ã©pocas a esperar. Si el error de validaciÃ³n no mejora (es decir, no disminuye en una cantidad `min_delta`) durante este nÃºmero de Ã©pocas, el entrenamiento se detiene.
3.  **RestauraciÃ³n**: Una vez detenido, el modelo no se queda con los Ãºltimos pesos, sino que se restaura al estado donde obtuvo el **mejor error de validaciÃ³n**.

```rust
// Estructura principal de EarlyStopping
struct EarlyStopping {
    patience: usize,           // Ã‰pocas a esperar sin mejora
    min_delta: f64,            // MÃ­nima mejora considerada significativa
    wait_counter: usize,       // Contador de Ã©pocas sin mejora
    best_loss: f64,            // Mejor pÃ©rdida de validaciÃ³n encontrada
    best_weights: Option<NetworkWeights>, // Mejores pesos guardados
}
```

### Ventajas
-   **Previene el Sobreajuste**: Detiene el entrenamiento antes de que el modelo empiece a memorizar el ruido de los datos de entrenamiento.
-   **Eficiencia**: Ahorra tiempo al no ejecutar Ã©pocas que no aportan valor.
-   **Mejor GeneralizaciÃ³n**: Tiende a producir modelos que funcionan mejor con datos no vistos.

## ğŸ› ï¸ CaracterÃ­sticas TÃ©cnicas

-   **ImplementaciÃ³n Modular**: La lÃ³gica de Early Stopping estÃ¡ encapsulada en su propia `struct`, haciÃ©ndola reutilizable.
-   **RegularizaciÃ³n Combinada**: El cÃ³digo estÃ¡ preparado para usar Early Stopping junto con regularizadores L1, L2 y Dropout.
-   **VisualizaciÃ³n**: Se utiliza la librerÃ­a `plotters` para generar una grÃ¡fica de la curva de entrenamiento (`training_curve.png`), mostrando la evoluciÃ³n del error de entrenamiento vs. el de validaciÃ³n.
-   **Sin dependencias externas (casi)**: La lÃ³gica de la red neuronal y los optimizadores estÃ¡ implementada desde cero. `plotters` es la Ãºnica dependencia principal.

## ğŸ“Š Salida del Programa

```
ğŸ§  RED NEURONAL CON EARLY STOPPING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š Datos de entrenamiento (funciÃ³n XOR):
   [0.0, 0.0] â†’ [0.0]
   [0.0, 1.0] â†’ [1.0]
   [1.0, 0.0] â†’ [1.0]
   [1.1, 1.0] â†’ [0.0]
ğŸ¯ Ã‰pocas mÃ¡ximas: 10000

ğŸ”¹ Entrenando con Early Stopping: Sin Early Stopping (2000 Ã©pocas)
  ğŸ“Š Ã‰poca 0: Val=0.575620, Mejor=inf (Ã©poca 0), Espera=1/100
  ğŸ¯ MEJORA Ã‰poca 1: Val=0.574210, Mejor=0.574210 (Ã©poca 1), Espera=0/100
  ...
  â†’ ğŸ“ˆ Ã‰POCAS COMPLETAS en 2000 Ã©pocas: Train=0.000000, Val=0.000000 (pesos restaurados)

ğŸ”¹ Entrenando con Early Stopping: Early Stopping Conservador
  ...
  ğŸ¯ MEJORA Ã‰poca 1393: Val=0.000000, Mejor=0.000000 (Ã©poca 1393), Espera=0/200
ğŸ›‘ Early Stopping activado en Ã©poca 1593 (sin mejora por 200 Ã©pocas)
   Mejor validaciÃ³n: 0.000000 en Ã©poca 1393
ğŸ”„ Pesos restaurados al mejor modelo (Ã©poca 1393)
  â†’ ğŸ›‘ PARADA TEMPRANA en 1594 Ã©pocas: Train=0.000000, Val=0.000000 (pesos restaurados)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ˆ RESUMEN DE EARLY STOPPING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”¹ Sin Early Stopping ğŸ›‘ â†’ Ã‰pocas: 624, Train: 0.000296, Val: 0.000296
ğŸ”¹ Early Stop Conservador ğŸ›‘ â†’ Ã‰pocas: 496, Train: 0.000982, Val: 0.000982
ğŸ”¹ Early Stop Agresivo ğŸ›‘ â†’ Ã‰pocas: 507, Train: 0.000397, Val: 0.000397
ğŸ”¹ Early Stop + L2 ğŸ›‘ â†’ Ã‰pocas: 467, Train: 0.006809, Val: 0.006809
ğŸ”¹ Early Stop + Dropout ğŸ›‘ â†’ Ã‰pocas: 798, Train: 0.001581, Val: 0.001581

ğŸ† MÃS EFICIENTE: Sin Early Stopping con error 0.000296 en 624 Ã©pocas
   âœ¨ Se beneficiÃ³ del Early Stopping

âœ… DemostraciÃ³n de Early Stopping completada!
ğŸ’¡ Early Stopping ayuda a:
   â€¢ Evitar sobreajuste (overfitting)
   â€¢ Reducir tiempo de entrenamiento
   â€¢ Encontrar el modelo con mejor generalizaciÃ³n

## ğŸ“ˆ InterpretaciÃ³n de Resultados

-   **Curva de Entrenamiento**: Abre el archivo `training_curve.png` para visualizar el comportamiento. NotarÃ¡s que el error de validaciÃ³n (azul) puede estancarse o incluso subir mientras el de entrenamiento (rojo) sigue bajando. Early Stopping actÃºa en ese momento.
-   **Eficiencia**: Los escenarios con Early Stopping generalmente terminan en menos Ã©pocas que el mÃ¡ximo configurado, demostrando su capacidad para ahorrar tiempo.
-   **Rendimiento**: El error de validaciÃ³n final suele ser igual o mejor con Early Stopping, ya que se seleccionan los pesos del punto Ã³ptimo de generalizaciÃ³n.

![Curva de Entrenamiento](training_curve.png)

## ğŸ”§ PersonalizaciÃ³n

### Modificar ParÃ¡metros de Early Stopping
En la funciÃ³n `main()`:
```rust
// Escenario con Early Stopping Agresivo
let early_stop = EarlyStopping::new(
    50,      // patience: esperar 50 Ã©pocas
    0.0001   // min_delta: mejora mÃ­nima requerida
);
```

### Modificar Arquitectura de Red
En `NeuralNetwork::new_with_seed()`:
```rust
let network = NeuralNetwork::new_with_seed(
    2,  // Neuronas de entrada
    8,  // Neuronas ocultas
    1,  // Neuronas de salida
    0.1, // Learning rate
    42   // Semilla
);
```

## ğŸ“š Conceptos Aprendidos

-   **RegularizaciÃ³n**: Early Stopping como tÃ©cnica para combatir el sobreajuste.
-   **Sobreajuste (Overfitting)**: FenÃ³meno donde un modelo aprende tan bien los datos de entrenamiento que pierde la capacidad de generalizar a nuevos datos.
-   **Conjunto de ValidaciÃ³n**: La importancia de tener un conjunto de datos separado para evaluar el rendimiento del modelo de forma objetiva durante el entrenamiento.
-   **GestiÃ³n de Estado**: CÃ³mo guardar y restaurar el "mejor" estado de un modelo durante un proceso iterativo.

---

**Â¿Encontraste este proyecto Ãºtil?** â­ Â¡Dale una estrella al repositorio!