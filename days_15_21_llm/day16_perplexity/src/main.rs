// MÃ©tricas de EvaluaciÃ³n: Perplexity
// DÃ­a 16: EvaluaciÃ³n de Modelos de Lenguaje

mod dataset;
mod ngram;
mod visualization;

use dataset::{load_africa_galore, tokenize_corpus};
use ngram::{
    calculate_perplexity_bigram, calculate_perplexity_trigram, calculate_perplexity_unigram,
    BigramModel, TrigramModel, UnigramModel,
};
use visualization::plot_perplexity_comparison;

fn main() {
    println!("ðŸ“ˆ Perplexity - DÃ­a 16");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("MÃ©tricas de EvaluaciÃ³n de Modelos de Lenguaje");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    // 1. Cargar dataset Africa Galore
    println!("ðŸ“¦ Cargando dataset Africa Galore...");
    let dataset_path = "../../datasets/africa_galore.json";
    let texts = match load_africa_galore(dataset_path) {
        Ok(texts) => {
            println!("âœ… Dataset cargado: {} textos", texts.len());
            texts
        }
        Err(e) => {
            eprintln!("âŒ Error cargando dataset: {}", e);
            eprintln!("ðŸ’¡ AsegÃºrate de ejecutar desde: days_15_21_llm/day16_perplexity/");
            eprintln!("ðŸ’¡ Y que el dataset estÃ© en: datasets/africa_galore.json");
            return;
        }
    };

    // 2. Tokenizar corpus
    println!("\nðŸ”¤ Tokenizando corpus...");
    let all_tokens = tokenize_corpus(&texts);
    println!("âœ… Total de tokens: {}", all_tokens.len());

    // Dividir en entrenamiento (80%) y prueba (20%)
    let split_index = (all_tokens.len() as f64 * 0.8) as usize;
    let train_tokens = &all_tokens[..split_index];
    let test_tokens = &all_tokens[split_index..];
    println!("âœ… Tokens de entrenamiento: {}", train_tokens.len());
    println!("âœ… Tokens de prueba: {}", test_tokens.len());

    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("ðŸŽ¯ Â¿QUÃ‰ ES PERPLEXITY?");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("\nðŸ“– Perplexity mide quÃ© tan 'sorprendido' estÃ¡ un modelo");
    println!("   ante nuevos datos. Es una medida de incertidumbre.");
    println!();
    println!("   FÃ³rmula: PPL = exp(-1/N * Î£ log P(palabra_i | contexto))");
    println!();
    println!("   ðŸŽ¯ Menor perplexity = Mejor modelo");
    println!("   - PPL = 1: PredicciÃ³n perfecta (imposible en la prÃ¡ctica)");
    println!("   - PPL = 100: El modelo tiene ~100 opciones equiprobables");
    println!("   - PPL = 1000+: Modelo muy confundido");
    println!();
    println!("   ðŸ’¡ InterpretaciÃ³n intuitiva:");
    println!("      Si PPL = 50, el modelo estÃ¡ tan sorprendido como si");
    println!("      tuviera que elegir entre 50 palabras igualmente probables");

    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("ðŸ”¬ ENTRENANDO Y EVALUANDO MODELOS");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

    // 3. Entrenar modelos
    println!("\nðŸŽ“ Entrenando modelo Unigram...");
    let unigram_model = UnigramModel::new(train_tokens);
    println!("âœ… Unigram entrenado");

    println!("ðŸŽ“ Entrenando modelo Bigram...");
    let bigram_model = BigramModel::new(train_tokens);
    println!("âœ… Bigram entrenado");

    println!("ðŸŽ“ Entrenando modelo Trigram...");
    let trigram_model = TrigramModel::new(train_tokens);
    println!("âœ… Trigram entrenado");

    // 4. Calcular perplexity en conjunto de prueba
    println!("\nðŸ“Š Calculando perplexity en conjunto de prueba...");
    let unigram_ppl = calculate_perplexity_unigram(&unigram_model, test_tokens);
    let bigram_ppl = calculate_perplexity_bigram(&bigram_model, test_tokens);
    let trigram_ppl = calculate_perplexity_trigram(&trigram_model, test_tokens);

    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("ðŸ“Š RESULTADOS: PERPLEXITY EN CONJUNTO DE PRUEBA");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("\n   Modelo      | Perplexity | InterpretaciÃ³n");
    println!("   ------------|------------|---------------");
    println!("   Unigram     | {:>10.2} | {}", unigram_ppl, interpret_perplexity(unigram_ppl));
    println!("   Bigram      | {:>10.2} | {}", bigram_ppl, interpret_perplexity(bigram_ppl));
    println!("   Trigram     | {:>10.2} | {}", trigram_ppl, interpret_perplexity(trigram_ppl));

    // 5. AnÃ¡lisis de mejora
    println!("\nðŸ“ˆ AnÃ¡lisis de mejora:");
    let bigram_improvement = ((unigram_ppl - bigram_ppl) / unigram_ppl) * 100.0;
    let trigram_improvement = ((bigram_ppl - trigram_ppl) / bigram_ppl) * 100.0;
    println!("   â€¢ Bigram vs Unigram: {:.1}% de mejora", bigram_improvement);
    println!("   â€¢ Trigram vs Bigram: {:.1}% de mejora", trigram_improvement);

    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("ðŸ“‰ ANÃLISIS: PERPLEXITY VS CANTIDAD DE DATOS");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

    // 6. Evaluar con diferentes cantidades de datos de entrenamiento
    let training_fractions = vec![0.2, 0.4, 0.6, 0.8, 1.0];
    let mut learning_curves = vec![
        ("Unigram", Vec::new()),
        ("Bigram", Vec::new()),
        ("Trigram", Vec::new()),
    ];

    println!("\nðŸ”¬ Entrenando modelos con diferentes cantidades de datos...");
    for &fraction in &training_fractions {
        let train_size = (train_tokens.len() as f64 * fraction) as usize;
        let partial_train = &train_tokens[..train_size];

        let unigram = UnigramModel::new(partial_train);
        let bigram = BigramModel::new(partial_train);
        let trigram = TrigramModel::new(partial_train);

        let unigram_ppl = calculate_perplexity_unigram(&unigram, test_tokens);
        let bigram_ppl = calculate_perplexity_bigram(&bigram, test_tokens);
        let trigram_ppl = calculate_perplexity_trigram(&trigram, test_tokens);

        learning_curves[0].1.push((fraction, unigram_ppl));
        learning_curves[1].1.push((fraction, bigram_ppl));
        learning_curves[2].1.push((fraction, trigram_ppl));

        println!("   {}% datos: Unigram={:.1}, Bigram={:.1}, Trigram={:.1}",
                 (fraction * 100.0) as u32, unigram_ppl, bigram_ppl, trigram_ppl);
    }

    println!("\nðŸ’¡ Observaciones:");
    println!("   â€¢ MÃ¡s datos de entrenamiento generalmente reducen perplexity");
    println!("   â€¢ Modelos de mayor orden (trigram) se benefician mÃ¡s de datos adicionales");
    println!("   â€¢ Hay rendimientos decrecientes: duplicar datos no duplica la mejora");

    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("ðŸ“Š GENERANDO VISUALIZACIONES");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

    // 7. Crear visualizaciÃ³n de comparaciÃ³n
    let model_names = vec!["Unigram", "Bigram", "Trigram"];
    let perplexities = vec![unigram_ppl, bigram_ppl, trigram_ppl];

    match plot_perplexity_comparison(&model_names, &perplexities, "perplexity_comparison.png") {
        Ok(_) => println!("\nâœ… GrÃ¡fica guardada: perplexity_comparison.png"),
        Err(e) => eprintln!("\nâŒ Error creando grÃ¡fica: {}", e),
    }

    // 8. Crear visualizaciÃ³n de curvas de aprendizaje
    match visualization::plot_learning_curves(&learning_curves, "learning_curves.png") {
        Ok(_) => println!("âœ… Curvas de aprendizaje guardadas: learning_curves.png"),
        Err(e) => eprintln!("âŒ Error creando curvas: {}", e),
    }

    println!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("ðŸŽ“ CONCLUSIONES");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("\nâœ… Lecciones aprendidas sobre Perplexity:");
    println!();
    println!("   1. ðŸ“ MÃ©trica estÃ¡ndar para evaluar modelos de lenguaje");
    println!("      - Permite comparar diferentes arquitecturas");
    println!("      - Independiente del tamaÃ±o del vocabulario (normalizada)");
    println!();
    println!("   2. ðŸŽ¯ Modelos de mayor contexto (trigram) tienen menor perplexity");
    println!("      - Capturan mÃ¡s patrones del lenguaje");
    println!("      - Pero requieren mÃ¡s datos para entrenar bien");
    println!();
    println!("   3. ðŸ“Š MÃ¡s datos = Mejor perplexity (hasta cierto punto)");
    println!("      - Importante tener suficientes datos de entrenamiento");
    println!("      - Los rendimientos decrecen con mÃ¡s datos");
    println!();
    println!("   4. âš ï¸  Limitaciones de perplexity:");
    println!("      - No mide coherencia semÃ¡ntica directamente");
    println!("      - Un modelo puede tener baja perplexity y aÃºn generar");
    println!("        texto sin sentido en contextos especÃ­ficos");
    println!("      - Debe complementarse con evaluaciÃ³n humana");
    println!();
    println!("   5. ðŸš€ PrÃ³ximos pasos:");
    println!("      - TokenizaciÃ³n avanzada (BPE) - DÃ­a 17");
    println!("      - Embeddings para capturar significado - DÃ­a 18");
    println!("      - Modelos neuronales (Transformers) - DÃ­as 19-21");

    println!("\nâœ… AnÃ¡lisis de perplexity completado!");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
}

/// Interpreta un valor de perplexity y retorna una descripciÃ³n
fn interpret_perplexity(ppl: f64) -> &'static str {
    if ppl < 10.0 {
        "Excelente"
    } else if ppl < 50.0 {
        "Muy bueno"
    } else if ppl < 100.0 {
        "Bueno"
    } else if ppl < 200.0 {
        "Aceptable"
    } else if ppl < 500.0 {
        "Regular"
    } else {
        "Pobre"
    }
}
